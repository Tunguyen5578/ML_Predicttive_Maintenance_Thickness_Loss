{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Logistic Regression - Pipeline Condition Classification\n",
        "## TASK 5: Baseline Model Evaluation\n",
        "\n",
        "**Date:** December 30, 2025  \n",
        "**Algorithm:** Logistic Regression  \n",
        "**Target:** Condition (Normal / Moderate / Critical)  \n",
        "**Problem Type:** Multi-class Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print('\u2713 Libraries loaded')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load train/test splits\n",
        "X_train = pd.read_csv('X_train.csv')\n",
        "X_test = pd.read_csv('X_test.csv')\n",
        "y_train = pd.read_csv('y_train.csv').values.ravel()\n",
        "y_test = pd.read_csv('y_test.csv').values.ravel()\n",
        "\n",
        "print('\u2713 Data loaded')\n",
        "print(f'Training set: {X_train.shape[0]} samples, {X_train.shape[1]} features')\n",
        "print(f'Test set: {X_test.shape[0]} samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale features (important for Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print('\u2713 Features scaled using StandardScaler')\n",
        "print(f'Mean: {X_train_scaled.mean():.4f}')\n",
        "print(f'Std: {X_train_scaled.std():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train Logistic Regression\n",
        "model = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    random_state=42,\n",
        "    multi_class='ovr',  # One-vs-Rest for multi-class\n",
        "    solver='lbfgs'\n",
        ")\n",
        "\n",
        "print('Training Logistic Regression...')\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print('\u2713 Model trained successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predictions\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Prediction probabilities\n",
        "y_test_proba = model.predict_proba(X_test_scaled)\n",
        "\n",
        "print('\u2713 Predictions completed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Evaluate Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print('='*60)\n",
        "print('LOGISTIC REGRESSION - PERFORMANCE METRICS')\n",
        "print('='*60)\n",
        "print(f'\\nTraining Accuracy:   {train_accuracy:.4f} ({train_accuracy*100:.2f}%)')\n",
        "print(f'Test Accuracy:       {test_accuracy:.4f} ({test_accuracy*100:.2f}%)')\n",
        "print(f'\\nOverfitting Check:   {train_accuracy - test_accuracy:.4f}')\n",
        "if train_accuracy - test_accuracy < 0.05:\n",
        "    print('Status: \u2713 Good generalization')\n",
        "else:\n",
        "    print('Status: \u26a0 Possible overfitting')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classification Report\n",
        "print('\\n' + '='*60)\n",
        "print('CLASSIFICATION REPORT - TEST SET')\n",
        "print('='*60)\n",
        "\n",
        "# Load target mapping for class names\n",
        "import json\n",
        "try:\n",
        "    with open('target_mapping.json', 'r') as f:\n",
        "        target_mapping = json.load(f)\n",
        "    class_names = [k for k, v in sorted(target_mapping.items(), key=lambda x: x[1])]\n",
        "except:\n",
        "    class_names = ['Class_0', 'Class_1', 'Class_2']\n",
        "\n",
        "print(classification_report(y_test, y_test_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=class_names, yticklabels=class_names,\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.title('Confusion Matrix - Logistic Regression', fontsize=14, fontweight='bold', pad=15)\n",
        "plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
        "plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix_logistic_regression.png', dpi=300, bbox_inches='tight')\n",
        "print('\u2713 Saved: confusion_matrix_logistic_regression.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Feature Coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature coefficients\n",
        "feature_names = X_train.columns\n",
        "coefficients = model.coef_\n",
        "\n",
        "print('Feature Coefficients by Class:')\n",
        "print('='*60)\n",
        "\n",
        "for i, class_name in enumerate(class_names):\n",
        "    print(f'\\n{class_name}:')\n",
        "    coef_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Coefficient': coefficients[i]\n",
        "    }).sort_values('Coefficient', key=abs, ascending=False)\n",
        "    print(coef_df.head(10).to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize top feature coefficients\n",
        "fig, axes = plt.subplots(1, len(class_names), figsize=(16, 5))\n",
        "if len(class_names) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, class_name in enumerate(class_names):\n",
        "    coef_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Coefficient': coefficients[i]\n",
        "    }).sort_values('Coefficient', key=abs, ascending=False).head(10)\n",
        "    \n",
        "    colors = ['green' if x > 0 else 'red' for x in coef_df['Coefficient']]\n",
        "    axes[i].barh(coef_df['Feature'], coef_df['Coefficient'], color=colors, alpha=0.7)\n",
        "    axes[i].set_xlabel('Coefficient', fontsize=11, fontweight='bold')\n",
        "    axes[i].set_title(f'Top 10 Features - {class_name}', fontsize=12, fontweight='bold')\n",
        "    axes[i].axvline(0, color='black', linewidth=0.8)\n",
        "    axes[i].grid(alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_coefficients_logistic_regression.png', dpi=300, bbox_inches='tight')\n",
        "print('\u2713 Saved: feature_coefficients_logistic_regression.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results\n",
        "results = {\n",
        "    'Model': 'Logistic Regression',\n",
        "    'Training_Accuracy': round(train_accuracy, 4),\n",
        "    'Test_Accuracy': round(test_accuracy, 4),\n",
        "    'Features': X_train.shape[1],\n",
        "    'Training_Samples': X_train.shape[0],\n",
        "    'Test_Samples': X_test.shape[0]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame([results])\n",
        "results_df.to_csv('logistic_regression_results.csv', index=False)\n",
        "print('\u2713 Saved: logistic_regression_results.csv')\n",
        "\n",
        "# Save predictions\n",
        "predictions_df = pd.DataFrame({\n",
        "    'True_Label': y_test,\n",
        "    'Predicted_Label': y_test_pred\n",
        "})\n",
        "\n",
        "# Add probability columns\n",
        "for i, class_name in enumerate(class_names):\n",
        "    predictions_df[f'Prob_{class_name}'] = y_test_proba[:, i]\n",
        "\n",
        "predictions_df.to_csv('logistic_regression_predictions.csv', index=False)\n",
        "print('\u2713 Saved: logistic_regression_predictions.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "### Model: Logistic Regression\n",
        "- **Algorithm:** Multi-class classification (One-vs-Rest)\n",
        "- **Solver:** LBFGS\n",
        "- **Scaling:** StandardScaler\n",
        "\n",
        "### Performance:\n",
        "- Check accuracy scores above\n",
        "- Review classification report for per-class metrics\n",
        "- Analyze confusion matrix for misclassifications\n",
        "\n",
        "### Feature Analysis:\n",
        "- Positive coefficients increase class probability\n",
        "- Negative coefficients decrease class probability\n",
        "- Larger absolute values = stronger influence\n",
        "\n",
        "### Files Generated:\n",
        "- confusion_matrix_logistic_regression.png\n",
        "- feature_coefficients_logistic_regression.png\n",
        "- logistic_regression_results.csv\n",
        "- logistic_regression_predictions.csv\n",
        "\n",
        "---\n",
        "**Logistic Regression Complete!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}