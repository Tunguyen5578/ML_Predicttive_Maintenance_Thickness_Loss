{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# XGBoost - Pipeline Condition Classification\n",
        "## TASK 5: Baseline Model Evaluation\n",
        "\n",
        "**Date:** December 30, 2025  \n",
        "**Algorithm:** XGBoost Classifier  \n",
        "**Target:** Condition (Normal / Moderate / Critical)  \n",
        "**Problem Type:** Multi-class Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print('\u2713 Libraries loaded')\n",
        "print(f'XGBoost version: {xgb.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load train/test splits\n",
        "X_train = pd.read_csv('X_train.csv')\n",
        "X_test = pd.read_csv('X_test.csv')\n",
        "y_train = pd.read_csv('y_train.csv').values.ravel()\n",
        "y_test = pd.read_csv('y_test.csv').values.ravel()\n",
        "\n",
        "print('\u2713 Data loaded')\n",
        "print(f'Training set: {X_train.shape[0]} samples, {X_train.shape[1]} features')\n",
        "print(f'Test set: {X_test.shape[0]} samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train XGBoost\n",
        "model = xgb.XGBClassifier(\n",
        "    n_estimators=100,           # Number of boosting rounds\n",
        "    max_depth=6,                # Maximum tree depth\n",
        "    learning_rate=0.1,          # Step size shrinkage\n",
        "    objective='multi:softprob', # Multi-class probability\n",
        "    random_state=42,            # Reproducibility\n",
        "    n_jobs=-1,                  # Use all CPU cores\n",
        "    eval_metric='mlogloss'      # Multi-class log loss\n",
        ")\n",
        "\n",
        "print('Training XGBoost...')\n",
        "model.fit(X_train, y_train)\n",
        "print('\u2713 Model trained successfully')\n",
        "print(f'Number of boosting rounds: {model.n_estimators}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predictions\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Prediction probabilities\n",
        "y_test_proba = model.predict_proba(X_test)\n",
        "\n",
        "print('\u2713 Predictions completed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Evaluate Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print('='*60)\n",
        "print('XGBOOST - PERFORMANCE METRICS')\n",
        "print('='*60)\n",
        "print(f'\\nTraining Accuracy:   {train_accuracy:.4f} ({train_accuracy*100:.2f}%)')\n",
        "print(f'Test Accuracy:       {test_accuracy:.4f} ({test_accuracy*100:.2f}%)')\n",
        "print(f'\\nOverfitting Check:   {train_accuracy - test_accuracy:.4f}')\n",
        "if train_accuracy - test_accuracy < 0.05:\n",
        "    print('Status: \u2713 Good generalization')\n",
        "elif train_accuracy - test_accuracy < 0.10:\n",
        "    print('Status: \u26a0 Slight overfitting')\n",
        "else:\n",
        "    print('Status: \u26a0 Overfitting detected')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classification Report\n",
        "print('\\n' + '='*60)\n",
        "print('CLASSIFICATION REPORT - TEST SET')\n",
        "print('='*60)\n",
        "\n",
        "# Load target mapping for class names\n",
        "import json\n",
        "try:\n",
        "    with open('target_mapping.json', 'r') as f:\n",
        "        target_mapping = json.load(f)\n",
        "    class_names = [k for k, v in sorted(target_mapping.items(), key=lambda x: x[1])]\n",
        "except:\n",
        "    class_names = ['Class_0', 'Class_1', 'Class_2']\n",
        "\n",
        "print(classification_report(y_test, y_test_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', \n",
        "            xticklabels=class_names, yticklabels=class_names,\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.title('Confusion Matrix - XGBoost', fontsize=14, fontweight='bold', pad=15)\n",
        "plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
        "plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix_xgboost.png', dpi=300, bbox_inches='tight')\n",
        "print('\u2713 Saved: confusion_matrix_xgboost.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature importance (gain-based)\n",
        "importance_dict = model.get_booster().get_score(importance_type='gain')\n",
        "\n",
        "# Create DataFrame\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': [importance_dict.get(f'f{i}', 0) for i in range(len(X_train.columns))]\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print('Feature Importance (Top 15):')\n",
        "print('='*60)\n",
        "print(feature_importance.head(15).to_string(index=False))\n",
        "\n",
        "# Save full feature importance\n",
        "feature_importance.to_csv('feature_importance_xgboost.csv', index=False)\n",
        "print('\\n\u2713 Saved: feature_importance_xgboost.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize top 15 features\n",
        "top_features = feature_importance.head(15)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "colors = plt.cm.Oranges(np.linspace(0.4, 0.8, len(top_features)))\n",
        "plt.barh(top_features['Feature'], top_features['Importance'], color=colors)\n",
        "plt.xlabel('Importance (Gain)', fontsize=12, fontweight='bold')\n",
        "plt.ylabel('Features', fontsize=12, fontweight='bold')\n",
        "plt.title('Top 15 Feature Importance - XGBoost', fontsize=14, fontweight='bold', pad=15)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(alpha=0.3, axis='x')\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_importance_plot_xgboost.png', dpi=300, bbox_inches='tight')\n",
        "print('\u2713 Saved: feature_importance_plot_xgboost.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Model Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display model parameters\n",
        "print('XGBoost Configuration:')\n",
        "print('='*60)\n",
        "print(f'Number of estimators: {model.n_estimators}')\n",
        "print(f'Max depth: {model.max_depth}')\n",
        "print(f'Learning rate: {model.learning_rate}')\n",
        "print(f'Objective: {model.objective}')\n",
        "print(f'Evaluation metric: {model.eval_metric}')\n",
        "print(f'Random state: {model.random_state}')\n",
        "print(f'\\nTotal features used: {model.n_features_in_}')\n",
        "print(f'Classes: {model.classes_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results\n",
        "results = {\n",
        "    'Model': 'XGBoost',\n",
        "    'Training_Accuracy': round(train_accuracy, 4),\n",
        "    'Test_Accuracy': round(test_accuracy, 4),\n",
        "    'N_Estimators': model.n_estimators,\n",
        "    'Max_Depth': model.max_depth,\n",
        "    'Learning_Rate': model.learning_rate,\n",
        "    'Features': X_train.shape[1],\n",
        "    'Training_Samples': X_train.shape[0],\n",
        "    'Test_Samples': X_test.shape[0]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame([results])\n",
        "results_df.to_csv('xgboost_results.csv', index=False)\n",
        "print('\u2713 Saved: xgboost_results.csv')\n",
        "\n",
        "# Save predictions\n",
        "predictions_df = pd.DataFrame({\n",
        "    'True_Label': y_test,\n",
        "    'Predicted_Label': y_test_pred\n",
        "})\n",
        "\n",
        "# Add probability columns\n",
        "for i, class_name in enumerate(class_names):\n",
        "    predictions_df[f'Prob_{class_name}'] = y_test_proba[:, i]\n",
        "\n",
        "predictions_df.to_csv('xgboost_predictions.csv', index=False)\n",
        "print('\u2713 Saved: xgboost_predictions.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "### Model: XGBoost Classifier\n",
        "- **Algorithm:** Gradient Boosting (optimized)\n",
        "- **Boosting rounds:** 100\n",
        "- **Max depth:** 6\n",
        "- **Learning rate:** 0.1\n",
        "- **Scaling:** Not required (tree-based model)\n",
        "\n",
        "### Performance:\n",
        "- Check accuracy scores above\n",
        "- Review classification report for per-class metrics\n",
        "- Analyze confusion matrix for misclassifications\n",
        "\n",
        "### Feature Importance:\n",
        "- Based on gain (improvement in loss function)\n",
        "- Higher values = more important features\n",
        "- Different from Random Forest (uses frequency)\n",
        "\n",
        "### Files Generated:\n",
        "- confusion_matrix_xgboost.png\n",
        "- feature_importance_plot_xgboost.png\n",
        "- feature_importance_xgboost.csv\n",
        "- xgboost_results.csv\n",
        "- xgboost_predictions.csv\n",
        "\n",
        "### Advantages:\n",
        "- Usually best performance\n",
        "- No feature scaling needed\n",
        "- Fast training with optimized algorithm\n",
        "- Handles imbalanced classes well\n",
        "- Built-in regularization\n",
        "\n",
        "### XGBoost vs Random Forest:\n",
        "- XGBoost: Sequential boosting, corrects errors\n",
        "- Random Forest: Parallel trees, averages predictions\n",
        "- XGBoost typically achieves higher accuracy\n",
        "\n",
        "---\n",
        "**XGBoost Complete!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}